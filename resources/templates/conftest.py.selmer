from typing import Iterator
from pyspark.sql import SparkSession
import pytest


@pytest.fixture(scope="session")
def spark() -> Iterator[SparkSession]:
    """Minimal, fast SparkSession for tests."""
    spark = (
        SparkSession.builder.master("local[1]")
        .appName("spark-proof-tests")
        .master("local[1]")
        .config("spark.network.timeout", "10000")
        .config("spark.executor.heartbeatInterval", "1000")
        .config("spark.driver.memory", "2g")
        .config("spark.sql.shuffle.partitions", "1")
        .config("spark.ui.showConsoleProgress", "false")
        .config("spark.ui.enabled", "false")
        .config("spark.ui.dagGraph.retainedRootRDDs", "1")
        .config("spark.ui.retainedJobs", "1")
        .config("spark.ui.retainedStages", "1")
        .config("spark.ui.retainedTasks", "1")
        .config("spark.sql.ui.retainedExecutions", "1")
        .config("spark.worker.ui.retainedExecutors", "1")
        .config("spark.worker.ui.retainedDrivers", "1")
        .config("spark.eventLog.enabled", "false")
        .config("spark.default.parallelism", "1")
        .config("spark.rdd.compress", "false")
        .config("spark.shuffle.compress", "false")
        .config("spark.dynamicAllocation.enabled", "false")
        .config("spark.executor.cores", "1")
        .config("spark.executor.instances", "1")
        .getOrCreate()
    )

    yield spark

    spark.stop()
